{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zana_test_task2_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDiWJBBERiew"
      },
      "source": [
        "## Predict a tag for stack overflow question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMPFbnYORYDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf308b2-7fa3-4d92-f05f-b99e7f4b1a7b"
      },
      "source": [
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 9.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvCilmQcRBs2"
      },
      "source": [
        "import collections\r\n",
        "import pathlib\r\n",
        "import re\r\n",
        "import string\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import losses\r\n",
        "from tensorflow.keras import preprocessing\r\n",
        "from tensorflow.keras import utils\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow_text as tf_text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP3PJFlLRSEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1008cb02-b31d-4d7a-a71d-c541b9ac920b"
      },
      "source": [
        "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\r\n",
        "dataset = utils.get_file(\r\n",
        "    'stack_overflow_16k.tar.gz',\r\n",
        "    data_url,\r\n",
        "    untar=True,\r\n",
        "    cache_dir='stack_overflow',\r\n",
        "    cache_subdir='')\r\n",
        "dataset_dir = pathlib.Path(dataset).parent"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\n",
            "6053888/6053168 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRxIEB_2Re9Z",
        "outputId": "10af9b66-e088-474d-d26b-c214d1dd90e9"
      },
      "source": [
        "list(dataset_dir.iterdir())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/tmp/.keras/stack_overflow_16k.tar.gz.tar.gz'),\n",
              " PosixPath('/tmp/.keras/README.md'),\n",
              " PosixPath('/tmp/.keras/test'),\n",
              " PosixPath('/tmp/.keras/train')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeGrKnYwSCV7",
        "outputId": "15ae6eb5-5cc4-42c9-a0bb-28b0413816c8"
      },
      "source": [
        "train_dir = dataset_dir/'train'\r\n",
        "list(train_dir.iterdir())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/tmp/.keras/train/java'),\n",
              " PosixPath('/tmp/.keras/train/csharp'),\n",
              " PosixPath('/tmp/.keras/train/javascript'),\n",
              " PosixPath('/tmp/.keras/train/python')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG2DJy7aSEpq",
        "outputId": "bbc98c95-cb8f-499e-ad2e-8a7910f0be1d"
      },
      "source": [
        "sample_file = train_dir/'python/1755.txt'\r\n",
        "with open(sample_file) as f:\r\n",
        "  print(f.read())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "why does this blank program print true x=true.def stupid():.    x=false.stupid().print x\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTqY5dBWSG_x",
        "outputId": "86c5660b-9070-4428-9657-0bfd0af503b2"
      },
      "source": [
        "batch_size = 32\r\n",
        "seed = 42\r\n",
        "\r\n",
        "raw_train_ds = preprocessing.text_dataset_from_directory(\r\n",
        "    train_dir,\r\n",
        "    batch_size=batch_size,\r\n",
        "    validation_split=0.2,\r\n",
        "    subset='training',\r\n",
        "    seed=seed)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 6400 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjd1iEBxSPkf",
        "outputId": "024a3a0e-2704-4e5c-d0b2-3f79ee225b95"
      },
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\r\n",
        "  for i in range(2):\r\n",
        "    print(\"Question: \", text_batch.numpy()[i])\r\n",
        "    print(\"Label:\", label_batch.numpy()[i])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question:  b'\"language change with keydown event on all form i develop an application that can change language between english and hungarian. this software work with .resx files and when the user presses f2 the labels, buttons, and other controls their text properties will be changed from the .resx file. ..it\\'s ok, but when i have more than one form open, naturally the keydown event changes those controls that are in the focused form. so my question is: how can i capture the f2 keystroke in all opened forms?\"\\n'\n",
            "Label: 0\n",
            "Question:  b'bubble sort without using temporary variable i want to sort both 1 dimensional and 2 dimensional array without using temp variable in blank..how to do it can anyone suggest\\n'\n",
            "Label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UEqNw0cU0vr",
        "outputId": "6907f0b1-2afc-4ab5-c144-4965f454890f"
      },
      "source": [
        "for i, label in enumerate(raw_train_ds.class_names):\r\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0 corresponds to csharp\n",
            "Label 1 corresponds to java\n",
            "Label 2 corresponds to javascript\n",
            "Label 3 corresponds to python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rK_hfQHU3xI",
        "outputId": "dc9d68fd-484b-45a1-dd85-1e43681b0d86"
      },
      "source": [
        "raw_val_ds = preprocessing.text_dataset_from_directory(\r\n",
        "    train_dir,\r\n",
        "    batch_size=batch_size,\r\n",
        "    validation_split=0.2,\r\n",
        "    subset='validation',\r\n",
        "    seed=seed)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 1600 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd3zPoGnU7AL",
        "outputId": "98e8069c-e759-4df2-a067-2eead6a60eae"
      },
      "source": [
        "test_dir = dataset_dir/'test'\r\n",
        "raw_test_ds = preprocessing.text_dataset_from_directory(\r\n",
        "    test_dir, batch_size=batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY_AM4OjU9aR"
      },
      "source": [
        "VOCAB_SIZE = 10000\r\n",
        "\r\n",
        "binary_vectorize_layer = TextVectorization(\r\n",
        "    max_tokens=VOCAB_SIZE,\r\n",
        "    output_mode='binary')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okZW-2Q7VA5E"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 250\r\n",
        "\r\n",
        "int_vectorize_layer = TextVectorization(\r\n",
        "    max_tokens=VOCAB_SIZE,\r\n",
        "    output_mode='int',\r\n",
        "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMP2VR4CVENL"
      },
      "source": [
        "# Make a text-only dataset (without labels), then call adapt\r\n",
        "train_text = raw_train_ds.map(lambda text, labels: text)\r\n",
        "binary_vectorize_layer.adapt(train_text)\r\n",
        "int_vectorize_layer.adapt(train_text)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA36s4tMVHSB"
      },
      "source": [
        "def binary_vectorize_text(text, label):\r\n",
        "  text = tf.expand_dims(text, -1)\r\n",
        "  return binary_vectorize_layer(text), label\r\n",
        "\r\n",
        "def int_vectorize_text(text, label):\r\n",
        "  text = tf.expand_dims(text, -1)\r\n",
        "  return int_vectorize_layer(text), label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KehejbjVK7K",
        "outputId": "f96f57b8-1029-42a2-8acd-3d3f266299ad"
      },
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) from the dataset\r\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\r\n",
        "first_question, first_label = text_batch[0], label_batch[0]\r\n",
        "print(\"Question\", first_question)\r\n",
        "print(\"Label\", first_label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question tf.Tensor(b'\"function expected error in blank for dynamically created check box when it is clicked i want to grab the attribute value.it is working in ie 8,9,10 but not working in ie 11,chrome shows function expected error..&lt;input type=checkbox checked=\\'checked\\' id=\\'symptomfailurecodeid\\' tabindex=\\'54\\' style=\\'cursor:pointer;\\' onclick=chkclickevt(this);  failurecodeid=\"\"1\"\" &gt;...function chkclickevt(obj) { .    alert(obj.attributes(\"\"failurecodeid\"\"));.}\"\\n', shape=(), dtype=string)\n",
            "Label tf.Tensor(2, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRKTH3IaVNnk",
        "outputId": "d6f50917-ce8f-46cb-fd7e-6d2f8ea5e247"
      },
      "source": [
        "print(\"'binary' vectorized question:\", \r\n",
        "      binary_vectorize_text(first_question, first_label)[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'binary' vectorized question: tf.Tensor([[1. 1. 1. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4FyPhfdVV_V",
        "outputId": "d9de7a16-7a9a-458e-cb4e-0208b29db240"
      },
      "source": [
        "print(\"'int' vectorized question:\",\r\n",
        "      int_vectorize_text(first_question, first_label)[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'int' vectorized question: tf.Tensor(\n",
            "[[  38  450   65    7   16   12  892  265  186  451   44   11    6  685\n",
            "     3   46    4 2062    2  485    1    6  158    7  479    1   26   20\n",
            "   158    7  479    1  502   38  450    1 1767 1763    1    1    1    1\n",
            "     1    1    1    1    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 250), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1vkDXTMVaBT",
        "outputId": "b2d43fe0-b21b-4ecb-d29b-08e6ca3d982b"
      },
      "source": [
        "print(\"1289 ---> \", int_vectorize_layer.get_vocabulary()[1289])\r\n",
        "print(\"313 ---> \", int_vectorize_layer.get_vocabulary()[313])\r\n",
        "print(\"Vocabulary size: {}\".format(len(int_vectorize_layer.get_vocabulary())))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1289 --->  roman\n",
            "313 --->  source\n",
            "Vocabulary size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL8D6YvOVe0k"
      },
      "source": [
        "binary_train_ds = raw_train_ds.map(binary_vectorize_text)\r\n",
        "binary_val_ds = raw_val_ds.map(binary_vectorize_text)\r\n",
        "binary_test_ds = raw_test_ds.map(binary_vectorize_text)\r\n",
        "\r\n",
        "int_train_ds = raw_train_ds.map(int_vectorize_text)\r\n",
        "int_val_ds = raw_val_ds.map(int_vectorize_text)\r\n",
        "int_test_ds = raw_test_ds.map(int_vectorize_text)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJutFdD3Vitz"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\r\n",
        "\r\n",
        "def configure_dataset(dataset):\r\n",
        "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkrp4NBGV1bs"
      },
      "source": [
        "binary_train_ds = configure_dataset(binary_train_ds)\r\n",
        "binary_val_ds = configure_dataset(binary_val_ds)\r\n",
        "binary_test_ds = configure_dataset(binary_test_ds)\r\n",
        "\r\n",
        "int_train_ds = configure_dataset(int_train_ds)\r\n",
        "int_val_ds = configure_dataset(int_val_ds)\r\n",
        "int_test_ds = configure_dataset(int_test_ds)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYWK0orbWUrA"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_BilksDWRgv"
      },
      "source": [
        "# train a simple bow linear model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6iLh-9zV35O",
        "outputId": "43185d8e-c330-4b29-c3f7-6143fd920391"
      },
      "source": [
        "binary_model = tf.keras.Sequential([layers.Dense(4)])\r\n",
        "binary_model.compile(\r\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    optimizer='adam',\r\n",
        "    metrics=['accuracy'])\r\n",
        "history = binary_model.fit(\r\n",
        "    binary_train_ds, validation_data=binary_val_ds, epochs=10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 5s 21ms/step - loss: 1.2416 - accuracy: 0.5359 - val_loss: 0.9120 - val_accuracy: 0.7794\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.8189 - accuracy: 0.8252 - val_loss: 0.7484 - val_accuracy: 0.8006\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6511 - accuracy: 0.8609 - val_loss: 0.6631 - val_accuracy: 0.8119\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5515 - accuracy: 0.8841 - val_loss: 0.6099 - val_accuracy: 0.8238\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4824 - accuracy: 0.9024 - val_loss: 0.5733 - val_accuracy: 0.8313\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4303 - accuracy: 0.9175 - val_loss: 0.5467 - val_accuracy: 0.8369\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3890 - accuracy: 0.9275 - val_loss: 0.5266 - val_accuracy: 0.8394\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3549 - accuracy: 0.9337 - val_loss: 0.5111 - val_accuracy: 0.8413\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.9393 - val_loss: 0.4989 - val_accuracy: 0.8425\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3013 - accuracy: 0.9467 - val_loss: 0.4891 - val_accuracy: 0.8413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2lk88dV6jf"
      },
      "source": [
        "# build a 1D ConVnet\r\n",
        "def create_model(vocab_size, num_labels):\r\n",
        "  model = tf.keras.Sequential([\r\n",
        "      layers.Embedding(vocab_size, 64, mask_zero=True),\r\n",
        "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\r\n",
        "      layers.GlobalMaxPooling1D(),\r\n",
        "      layers.Dense(num_labels)\r\n",
        "  ])\r\n",
        "  return model\r\n",
        "\r\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_MsJC9BWFrY",
        "outputId": "a03d05ab-160e-4ca7-f235-daa2dc90f958"
      },
      "source": [
        "# vocab_size is VOCAB_SIZE + 1 since 0 is used additionally for padding.\r\n",
        "int_model = create_model(vocab_size=VOCAB_SIZE + 1, num_labels=4)\r\n",
        "int_model.compile(\r\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    optimizer='adam',\r\n",
        "    metrics=['accuracy'])\r\n",
        "history = int_model.fit(int_train_ds, validation_data=int_val_ds, epochs=5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 9s 41ms/step - loss: 1.2992 - accuracy: 0.3882 - val_loss: 0.7545 - val_accuracy: 0.6900\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 6s 29ms/step - loss: 0.6917 - accuracy: 0.7180 - val_loss: 0.5446 - val_accuracy: 0.7944\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 6s 29ms/step - loss: 0.4228 - accuracy: 0.8656 - val_loss: 0.4894 - val_accuracy: 0.8094\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 6s 29ms/step - loss: 0.2417 - accuracy: 0.9399 - val_loss: 0.4904 - val_accuracy: 0.8112\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 6s 29ms/step - loss: 0.1212 - accuracy: 0.9787 - val_loss: 0.5126 - val_accuracy: 0.8069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7kKB5FfWmIY"
      },
      "source": [
        "## Compare the two models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCQMJelBWJLm",
        "outputId": "5ba048bd-8429-4de7-9260-2f5e3b38eaf3"
      },
      "source": [
        "binary_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 40004     \n",
            "=================================================================\n",
            "Total params: 40,004\n",
            "Trainable params: 40,004\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcGcH9mxWupB",
        "outputId": "2831699d-e7f7-49ba-e9c3-86fc04bc7880"
      },
      "source": [
        "int_model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          640064    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, None, 64)          20544     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 660,868\n",
            "Trainable params: 660,868\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6LMWPvCW9ua"
      },
      "source": [
        "## evaluate the models on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5CXhXGhWzRA",
        "outputId": "cee90aaa-0846-498e-9929-349840d91a8d"
      },
      "source": [
        "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_ds)\r\n",
        "int_loss, int_accuracy = int_model.evaluate(int_test_ds)\r\n",
        "\r\n",
        "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))\r\n",
        "print(\"Int model accuracy: {:2.2%}\".format(int_accuracy))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 4s 14ms/step - loss: 0.5175 - accuracy: 0.8139\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.5247 - accuracy: 0.8061\n",
            "Binary model accuracy: 81.39%\n",
            "Int model accuracy: 80.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74IYnQ1RXR31"
      },
      "source": [
        "## export the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qGBcVTkXDXm",
        "outputId": "7025e49e-56f0-4404-b47a-5e6141b2bc58"
      },
      "source": [
        "export_model = tf.keras.Sequential(\r\n",
        "    [binary_vectorize_layer, binary_model,\r\n",
        "     layers.Activation('sigmoid')])\r\n",
        "\r\n",
        "export_model.compile(\r\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\r\n",
        "    optimizer='adam',\r\n",
        "    metrics=['accuracy'])\r\n",
        "\r\n",
        "# Test it with `raw_test_ds`, which yields raw strings\r\n",
        "loss, accuracy = export_model.evaluate(raw_test_ds)\r\n",
        "print(\"Accuracy: {:2.2%}\".format(binary_accuracy))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 4s 14ms/step - loss: 0.5142 - accuracy: 0.8145\n",
            "Accuracy: 81.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-_vNhxwXXCa"
      },
      "source": [
        "# the model now can take raw strings as input\r\n",
        "def get_string_labels(predicted_scores_batch):\r\n",
        "  predicted_int_labels = tf.argmax(predicted_scores_batch, axis=1)\r\n",
        "  predicted_labels = tf.gather(raw_train_ds.class_names, predicted_int_labels)\r\n",
        "  return predicted_labels"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12TWUczvXhZa",
        "outputId": "baf1e282-3c62-40dd-a7ef-de94d474ce04"
      },
      "source": [
        "# run on new data\r\n",
        "inputs = [\r\n",
        "    \"how do I extract keys from a dict into a list?\",  # python\r\n",
        "    \"debug public static void main(string[] args) {...}\",  # java\r\n",
        "]\r\n",
        "predicted_scores = export_model.predict(inputs)\r\n",
        "predicted_labels = get_string_labels(predicted_scores)\r\n",
        "for input, label in zip(inputs, predicted_labels):\r\n",
        "  print(\"question: \", input)\r\n",
        "  print(\"prediction: \", label.numpy())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question:  how do I extract keys from a dict into a list?\n",
            "prediction:  b'python'\n",
            "question:  debug public static void main(string[] args) {...}\n",
            "prediction:  b'java'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}